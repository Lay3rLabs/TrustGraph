\section{Collective Intelligence through Verifiable Computation}

Traditional DAO voting compresses complex community preferences into binary yes/no decisions on pre-formed proposals. This compression discards valuable signal: the reasoning behind positions, conditions for support, suggested improvements, and expertise-weighted confidence. Communities actually possess rich collective intelligence. The limitation lies in aggregation mechanisms that can process only the simplest signals.

Verifiable Services enable high-bandwidth preference expression and sophisticated aggregation without sacrificing verifiability. This section explores how DAOs can tap their collective intelligence at unprecedented resolution.

\subsection{Semantically Rich Preference Expression}

Moving beyond binary voting requires accepting diverse input types while maintaining determinism. Citizens express preferences through multiple channels:

\textbf{Structured rubrics:} Multi-dimensional evaluation on defined criteria (feasibility, impact, alignment, risk) with weighted importance based on evaluator expertise.

\textbf{Preference rankings:} Ordering multiple options, expressing intensity of preference, and indicating acceptable alternatives for more nuanced collective decision-making.

\textbf{Conditional commitments:} Support contingent on specific modifications, resource availability, or concurrent decisions, enabling complex negotiation through governance.

\textbf{Resource allocation:} Distribution of budgets across proposals, projects, or teams based on perceived value, creating market-like signals within governance.

These inputs can be collected through standardized interfaces that ensure parseability while allowing expression flexibility. The key is defining clear schemas that balance expressiveness with computational tractability.

\subsection{Deterministic Processing Pipelines}

Verifiable Services process these rich inputs through deterministic pipelines. Every operation must be reproducible:

\textbf{1. Input validation and normalization:} Check signatures, verify eligibility, standardize formats, handle missing data consistently.

\textbf{2. Weight computation:} Calculate participant weights based on tokens, attestations, participation history, expertise in relevant domains.

\textbf{3. Aggregation logic:} Apply voting rules (quadratic, conviction, ranked choice), resolve conflicts and ties, compute confidence intervals.

\textbf{4. Output generation:} Produce canonical results, generate proof artifacts, create audit trails.

Critical: the pipeline must be deterministic. Given the same inputs, every operator must produce identical outputs. This requires:

\begin{itemize}
\item Fixed software versions with pinned dependencies
\item Deterministic randomness from agreed seeds
\item Explicit handling of edge cases (ties, timeouts, malformed inputs)
\item Canonical ordering for all operations
\end{itemize}

\subsection{Preference Learning and Synthesis}

Modern ML can be incorporated deterministically into governance:

\textbf{Fixed model inference:} Models are treated as deterministic functions. The model, weights, quantization, processing seeds, and software stack are fixed and made public. All operators use identical configurations and can reproduce each others' inferences. Citizens can audit outputs by running the model themselves.

\textbf{Structured acceptance:} Rather than trying to achieve bit-perfect neural network reproducibility, the system can accept outputs within defined tolerances. If all operators' outputs fall within acceptable bounds (e.g., sentiment scores within 0.01), the median is taken as canonical. This balances determinism with practical implementation.

\textbf{Progressive synthesis:} Models can identify preference clusters, extract common themes from discussions, suggest compromise proposals, predict proposal outcomes, and generate explanations for recommendations. These become inputs to human decision-making rather than automated decisions themselves.

\subsection{Case Study: Proposal Prioritization Pipeline}

Consider a DAO with 100+ monthly proposals that needs systematic prioritization:

\textbf{Stage 1: Collection (Approximate time: 3 days)}
\begin{itemize}
\item Proposers submit structured proposals with required fields
\item Members provide multi-dimensional evaluations
\item Experts with relevant attestations provide detailed reviews
\item Models extract themes from forum discussions
\end{itemize}

\textbf{Stage 2: Processing (Approximate time: 1 hour)}
\begin{itemize}
\item Aggregate evaluations weighted by expertise attestations
\item Calculate overall priority scores using community-defined formula
\item Cluster proposals by theme and interdependencies
\item Generate conflicts and synergy analysis
\end{itemize}

\textbf{Stage 3: Synthesis (Approximate time: 30 minutes)}
\begin{itemize}
\item Produce ranked priority list with confidence scores
\item Identify proposals ready for funding vs. needing iteration
\item Generate summary report with key insights
\item Create merkle tree of results for on-chain verification
\end{itemize}

\textbf{Stage 4: Execution (Approximate time: 1 day)}
\begin{itemize}
\item On-chain contract verifies operator signatures
\item Timelocked window for challenges
\item Automatic funding for approved proposals
\item Feedback to proposers on improvements needed
\end{itemize}

\textbf{Performance analysis:}
\begin{itemize}
\item \textbf{Latency:} Approximately 5 days end-to-end including timelock (dominated by preference collection period)
\item \textbf{Computational cost:} Off-chain processing approximately 1,000Ã— cheaper than on-chain
\item \textbf{On-chain gas:} Approximately 750k to 1.0M gas for verification and execution (versus estimated 210M+ gas for naive on-chain implementation)
\item \textbf{Throughput:} Can process 1,000+ proposals with 10,000+ evaluations
\end{itemize}

These are order-of-magnitude estimates based on architectural analysis. Actual performance will vary with implementation details, but the dramatic improvement over on-chain computation remains consistent.

\subsection{Future-Proofing with Zero-Knowledge ML}

Looking forward, Zero-Knowledge Machine Learning (ZKML) may replace Verifiable Services for model inference in some cases. ZKML would enable provers to generate cryptographic proofs of model inference that contracts can verify directly. This would eliminate trust in off-chain execution for those steps once performance becomes viable, replacing economic guarantees with cryptographic ones.

\subsection{Where This Connects}

Section 4 supplies the attestation graph that the pipeline reads. Section 6 turns accepted recommendations and constraint checks into Policy as Code triggers. Section 7 provides concrete validation through the pioneering TrustGraph implementation, demonstrating how these theoretical constructs operate in practice.
